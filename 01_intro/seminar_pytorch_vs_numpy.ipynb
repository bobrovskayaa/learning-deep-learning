{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"static/pytorch-vs-numpy-logo.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch vs. NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` is the fundamental package for **scientific computing** in Python. It provides a **multidimensional array** object (and other) for fast operations on arrays, including mathematical, logical, shape manipulation, etc. We hope you're familiar with NumPy. If you feel some gaps in knowledge check out [this tutorial](https://docs.scipy.org/doc/numpy-1.15.0/user/quickstart.html).\n",
    "\n",
    "\n",
    "Today we'll explore **PyTorch** library. PyTorch is also a scientific computing package (like NumPy), but it has two awesome features:\n",
    "- Automatic differentiation (very useful for deep learning)\n",
    "- GPU support for calculations\n",
    "\n",
    "\n",
    "Actually PyTorch has great features. Later on we'll use them to build neural networks, but for now let's consider it just like a scientific computing package. Let's start with installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is pretty easy to install:\n",
    "1. Go to [pytorch.org](https://pytorch.org) and scroll down to **\"Quick start locally\"** section.\n",
    "2. Choose options suitable for you. E.g.:\n",
    "    - PyTorch Build: **Stable (1.0)**\n",
    "    - Your OS: **Mac**\n",
    "    - Package: **Pip**\n",
    "    - Language: **Python 3.7** (check *your* python version via terminal `$ python3 --version`)\n",
    "    - CUDA: **None** (if you don't have GPU)\n",
    "3. Just run given command from termial. E.g.: `$ pip3 install torch torchvision`.\n",
    "4. PyTorch is quite big (especially CUDA versions), so you can have a cup of coffee while it's downloading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lifehack**: you can run termial commands directly from notebooks providing `!` in the beginning of the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify proper installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy installation is much easier:\n",
    "1. Run `$ pip3 install numpy`\n",
    "2. That's it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify proper installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning PyTorch like robots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all love **machine learning**, so let's try to study PyTorch in a *supervised learning* manner. Here're some pairs of examples for NumPy and corresponding PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_numpy = np.array([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]\n",
    "])\n",
    "\n",
    "print(\"x_numpy = \\n{}\\n\".format(x_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]\n",
    "])\n",
    "\n",
    "print(\"x_torch = \\n{}\\n\".format(x_torch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_numpy[0, 0] = \\n{}\\n\".format(x_numpy[0, 0]))\n",
    "print(\"x_numpy[:, 0] = \\n{}\\n\".format(x_numpy[:, 0]))\n",
    "print(\"x_numpy[:2, 1:3] = \\n{}\\n\".format(x_numpy[:2, 1:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_torch[0, 0] = \\n{}\\n\".format(x_torch[0, 0]))\n",
    "print(\"x_torch[:, 0] = \\n{}\\n\".format(x_torch[:, 0]))\n",
    "print(\"x_torch[:2, 1:3] = \\n{}\\n\".format(x_torch[:2, 1:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_numpy ** 2 = \\n{}\\n\".format(x_numpy ** 2))\n",
    "print(\"np.cos(x_numpy) = \\n{}\\n\".format(np.cos(x_numpy)))\n",
    "print(\"x_numpy.mean(axis=0) = \\n{}\\n\".format(x_numpy.mean(axis=0)))\n",
    "print(\"x_numpy.T = \\n{}\\n\".format(x_numpy.T))\n",
    "print(\"x_numpy.reshape(1, -1) = \\n{}\\n\".format(x_numpy.reshape(1, -1)))\n",
    "print(\"x_numpy.flatten() = \\n{}\\n\".format(x_numpy.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_torch ** 2 = \\n{}\\n\".format(x_torch ** 2))\n",
    "print(\"np.cos(x_torch) = \\n{}\\n\".format(torch.cos(x_torch)))\n",
    "print(\"x_torch.mean(dim=0) = \\n{}\\n\".format(x_torch.mean(dim=0)))\n",
    "print(\"x_torch.t() = \\n{}\\n\".format(x_torch.t()))\n",
    "print(\"x_torch.reshape(1, -1) = \\n{}\\n\".format(x_torch.reshape(1, -1)))\n",
    "print(\"x_torch.flatten() = \\n{}\\n\".format(x_torch.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"np.arange(3) = \\n{}\\n\".format(np.arange(3)))\n",
    "print(\"np.linspace(0.0, 1.0, num=9).reshape(3, 3) = \\n{}\\n\".format(np.linspace(0.0, 1.0, num=9).reshape(3, 3)))\n",
    "print(\"np.ones() = \\n{}\\n\".format(np.ones((2, 5))))\n",
    "print(\"np.random.rand(3, 2) = \\n{}\\n\".format(np.random.rand(3, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch.arange(3) = \\n{}\\n\".format(torch.arange(3)))\n",
    "print(\"torch.linspace(0.0, 1.0, steps=9).reshape(3, 3) = \\n{}\\n\".format(torch.linspace(0.0, 1.0, steps=9).reshape(3, 3)))\n",
    "print(\"torch.ones() = \\n{}\\n\".format(torch.ones((2, 5))))\n",
    "print(\"torch.random.rand(3, 2) = \\n{}\\n\".format(torch.rand(3, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 arrays/tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numpy = np.arange(0, 9).reshape(3, 3)\n",
    "y_numpy = np.linspace(0.0, 1.0, num=9).reshape(3, 3)\n",
    "\n",
    "print(\"x = \\n{}\\n\".format(x_numpy))\n",
    "print(\"y = \\n{}\\n\".format(y_numpy))\n",
    "print(\"x * y = \\n{}\\n\".format(x_numpy * y_numpy))\n",
    "print(\"x.dot(y) = \\n{}\\n\".format(x_numpy.dot(y_numpy)))\n",
    "print(\"np.concatenate([x, y], axis=1) = \\n{}\\n\".format(np.concatenate([x_numpy, y_numpy], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.arange(0, 9).reshape(3, 3).type(torch.float)\n",
    "y_torch = torch.linspace(0.0, 1.0, steps=9).reshape(3, 3)\n",
    "\n",
    "print(\"x = \\n{}\\n\".format(x_torch))\n",
    "print(\"y = \\n{}\\n\".format(y_torch))\n",
    "print(\"x * y = \\n{}\\n\".format(x_torch * y_torch))\n",
    "print(\"x.mm(y) = \\n{}\\n\".format(x_torch.mm(y_torch)))\n",
    "print(\"torch.cat([x, y], axis=1) = \\n{}\\n\".format(torch.cat([x_torch, y_torch], dim=1)))\n",
    "# print(\" = \\n{}\\n\".format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are differences?\n",
    "<img src=\"static/spiderman-meme.jpg\" width=500px align=\"center\"/>\n",
    "\n",
    "On the first sight PyTorch is about replacing `np.` with `torch.`. In most cases it's really true, but there are some more *key* differences:\n",
    "\n",
    "- by default NumPy creates float arrays with float64 dtype; PyTorch's default dtype is float32\n",
    "- `axis` in NumPy [`x.mean(axis=0)`] vs. `dim` in PyTorch [`x.mean(dim=0)`]\n",
    "- some functions' naming [e.g. `np.concatenate` vs. `torch.cat`]\n",
    "\n",
    "All these differences can be easily googled or found in awesome [PyTorch docs](https://pytorch.org/docs/stable/index.html). Checkout [this repository](https://github.com/wkentaro/pytorch-for-numpy-users) where all differences are listed in a table. If you still have questions, you can ask them on [PyTorch forum](https://discuss.pytorch.org) (it's alive and questions are frequently answered).\n",
    "\n",
    "So now you can ask: **why the hell should I use PyTorch instead of NumPy?** Actually PyTorch has some wonderful features, but we'll discuss them a bit later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy -> PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numpy = np.arange(9).reshape(3, 3)\n",
    "x_torch = torch.from_numpy(x_numpy)\n",
    "\n",
    "print(\"x_torch = \\n{}\\n\".format(x_torch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch -> NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.arange(9).reshape(3, 3)\n",
    "x_numpy = x_torch.numpy()\n",
    "\n",
    "print(\"x_numpy = \\n{}\\n\".format(x_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inplace operations. In PyTorch you can peform inplace operations (no copying). Many tensor methods have their inplace twins with `_` symbol in the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(5).type(torch.float)\n",
    "print(\"[before] x = {}\".format(x))\n",
    "\n",
    "x.sqrt_()\n",
    "print(\"[after]  x = {}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(5).type(torch.float)\n",
    "print(\"[before] x = {}\".format(x))\n",
    "\n",
    "x.zero_()\n",
    "print(\"[after]  x = {}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1 (1 point).** Drawing with PyTorch\n",
    "\n",
    "Implement this function and plot it using matplotlib:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "x = 16 \\sin^3(t) \\\\\n",
    "y = 13\\cos(t) - 5\\cos(2t) - 2\\cos(3t) - \\cos(4t) \\\\\n",
    "\\end{cases}\n",
    ",~ t \\in [0, 2\\pi]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0.0, 2 * np.pi, 100)\n",
    "\n",
    "x = # your code here\n",
    "y = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.numpy(), y.numpy(), c='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature of PyTorch is that it can **differentiate (almost) any expression written** in PyTorch.\n",
    "\n",
    "For example you have function $f(x) = x^2$. You want to calculate partial detivative $\\frac{\\partial f}{\\partial x}$. PyTorch allows you to do it in 3 lines! Look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)  # tells PyTorch that we'll need gradient of this tensor\n",
    "f_x = x ** 2  # run our function\n",
    "f_x.backward()  # calculate gradient\n",
    "\n",
    "print(\"df/dx = {}\".format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salt is that $f(x)$ can be any (almost) any function you want (e.g. your neural network). It totally looks like magic. More on PyTorch automatic differentiation read [here](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "plt.scatter(boston.data[:, -1], boston.target)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to torch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(boston.data[:, -1]).type(torch.float)\n",
    "x = (x - x.mean()) / x.std()  # normalization\n",
    "\n",
    "y = torch.from_numpy(boston.target).type(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-dimensional linear regression is formulated like this:\n",
    "$$\\normalsize y^{pred} = wx + b$$\n",
    "where $x$ - is a feature, $w, b$ - model parameters (weight and bias), and $y^{pred}$ - model's prediction.\n",
    "\n",
    "As a loss function we'll use **Mean Square Error** (MSE):\n",
    "$$MSE(y, y^{pred}) = \\frac{1}{N}\\sum_{i=0}^{N-1}(y_{i} - y_{i}^{pred}) ^ 2$$\n",
    "where $N$ - is a length of training set.\n",
    "\n",
    "To train our model, we'll use **Gradient Descent** (GD):\n",
    "$$\\normalsize w_{i} = w_{i - 1} - \\eta \\frac{\\partial loss}{\\partial w_{i - 1}}$$\n",
    "\n",
    "$$\\normalsize b_{i} = b_{i - 1} - \\eta \\frac{\\partial loss}{\\partial b_{i - 1}}$$\n",
    "where $\\eta$ - is a learning rate.\n",
    "\n",
    "But we're not going to calculate this partial derivative by hand. PyTorch will do it for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "lr = 0.01\n",
    "n_iters = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(n_iters):\n",
    "    # forward pass\n",
    "    y_pred = w * x + b\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = torch.mean((y - y_pred) ** 2)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # calculate gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # make gradient step\n",
    "    w.data = w.data - lr * w.grad.detach()  # detaching tensor from computational graph\n",
    "    b.data = b.data - lr * b.grad.detach()  #\n",
    "    \n",
    "    # zero gradients (otherwise they'll accumulate)\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    # visualization\n",
    "    if i % 10 == 0:\n",
    "        clear_output(True)\n",
    "        \n",
    "        print(\"loss: {:.04}\".format(loss.item()))\n",
    "        \n",
    "        # training set\n",
    "        plt.scatter(x.numpy(), y.numpy())\n",
    "        \n",
    "        # our predictions\n",
    "        plt.scatter(x.numpy(), y_pred.detach().numpy(), color='red')\n",
    "        \n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.show()\n",
    "    \n",
    "        \n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"iters\")\n",
    "plt.ylabel(\"loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (1 point). Linear regression with polynomial features\n",
    "\n",
    "As you can see above simple linear regression doesn't fit data well. Let's add polynomial features:\n",
    "$$\\normalsize y^{pred} = \\sum_{i=0}^{D-1}w_{i}x^{i}$$\n",
    "\n",
    "To get total score for this task:\n",
    " - choose any $D$ you want and make loss **< 30.0**.\n",
    " - answer the question: \"why don't we have bias (b) here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (2 points). Earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big earthquake happened! Seismic sensors fixed heatmap of underground activity. You can find this map on the path `./data/earthquake-heatmap.npy`.\n",
    "Read earthquake heatmap and draw it with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_heatmap = # your code here (use np.load)\n",
    "\n",
    "shape = earthquake_heatmap.shape\n",
    "print(\"shape: {}\".format(shape))\n",
    "\n",
    "plt.imshow(earthquake_heatmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to find coordinates of **earthquake epicenter** and **radius of seismic activity**.\n",
    "\n",
    "Possibly, your first thoughts will be: \"Hmm, epicenter I'll find by applying argmax for both dimensions. For radius I can write for-loop and... blablabla\". Such methods are okay, but we'll apply more **SCIENTIFIC** (actually not) method here. Scheme of proposed method is below.\n",
    "\n",
    "\n",
    "<img src=\"static/earthquake-method.png\" align=\"center\"/>\n",
    "\n",
    "We'll fit 2D gaussian to our earthquake heatmap.\n",
    "\n",
    "Overall algorithm is like this:\n",
    "1. generate 2D gaussian heatmap for current $\\mu$ and $\\sigma$ \n",
    "2. calculate per-pixel MSE of generated heatmap and earthquake heatmap\n",
    "3. calculate partial derivatives $\\frac{\\partial{loss}}{\\partial{\\mu}}$, $\\frac{\\partial{loss}}{\\partial{\\sigma}}$ and make gradient descent step to minimize loss\n",
    "4. go to step (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate heatmap we'll need Probability Dense Function (PDF) of independent 2D normal distribution:\n",
    "\n",
    "$$p(x_1, x_2) = \\frac{1}{2\\pi \\sigma_1 \\sigma_2}\\exp\\left[{-\\frac{(x_1 - \\mu_1)^2}{2\\sigma_1^2} - \\frac{(x_2 - \\mu_2)^2}{2\\sigma_2^2}}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement missing parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_2d_pdf(coords, mu, sigma):\n",
    "    \"\"\"Independent 2D normal distribution PDF\n",
    "    \n",
    "    Args:\n",
    "        coords (tensor of shape (N, 2)): coordinates, where to calculate function\n",
    "        mu (tensor of shape (2,)): mu values\n",
    "        sigma (tensor of shape (2,)): sigma values\n",
    "        \n",
    "    \"\"\"\n",
    "    normalization = # your code here\n",
    "    exp = # your code here\n",
    "    return exp / normalization\n",
    "\n",
    "\n",
    "def draw_heatmap(mu, sigma, shape):\n",
    "    xx, yy = torch.meshgrid(torch.arange(shape[0]), torch.arange(shape[1]))\n",
    "    grid = torch.stack([xx, yy], dim=-1).type(torch.float32)\n",
    "    grid = grid.reshape((-1, 2))\n",
    "    \n",
    "    heatmap = gaussian_2d_pdf(grid, mu, sigma)\n",
    "    heatmap = heatmap.reshape(*shape)\n",
    "    \n",
    "    heatmap = (heatmap - heatmap.mean()) / heatmap.std()\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate heatmap with any $\\mu$ and $\\sigma$; shape same as earthquake heatmap: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = # your code here\n",
    "sigma = # your code here\n",
    "\n",
    "heatmap = # your code here\n",
    "\n",
    "plt.imshow(heatmap.numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters of your model (initialize them with reasonable values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = # your code here\n",
    "sigma = # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build optimization loop and fit `mu` and `sigma`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- Plot your map and loss curve every n-th iteration\n",
    "- Tune learning rate\n",
    "- Try different initializations of $\\mu$ and $\\sigma$\n",
    "- Play with different number of iterations\n",
    "- Try Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
